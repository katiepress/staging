<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kpress R Blog</title>
    <link>/</link>
    <description>Recent content on Kpress R Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 03 Jan 2021 21:13:14 -0500</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Trust No One</title>
      <link>/blog/2021-01-03-trust-no-one/</link>
      <pubDate>Sun, 03 Jan 2021 21:13:14 -0500</pubDate>
      
      <guid>/blog/2021-01-03-trust-no-one/</guid>
      <description>In the last two episodes, I created an X-Files episode dataset and web-scraped episode scripts. Now it’s time for some real text analysis. Most of this is going to be based on Julia Silge’s work on tidy text mining, which can be found in her free eBook. And of course, all of this is based on the principles of tidy data - see this paper by tidyverse author Hadley Wickham for more details.</description>
    </item>
    
    <item>
      <title>I Want To Believe</title>
      <link>/blog/2021-01-03-the-truth-is-out-there-part-ii/</link>
      <pubDate>Sun, 01 Nov 2020 21:13:14 -0500</pubDate>
      
      <guid>/blog/2021-01-03-the-truth-is-out-there-part-ii/</guid>
      <description>In the last “episode” I created a dataset of X-Files episodes using web scraping. The simple episode descriptions are not going to give me the depth of information I need for a real text analysis, so it’s time to get some more data!
Many of the X-Files episode transcripts are available online, so I found a website I could use to scrape most of the text I need. First, I’m going to create a list of episode links that I can use to download the transcripts.</description>
    </item>
    
    <item>
      <title>The Truth Is Out There</title>
      <link>/blog/2021-01-03-the-truth-is-out-there/</link>
      <pubDate>Sun, 04 Oct 2020 21:13:14 -0500</pubDate>
      
      <guid>/blog/2021-01-03-the-truth-is-out-there/</guid>
      <description>I’ve had an idea floating around for a while to do a tidy text analysis on X-Files episode scripts. The X-Files has been around long enough that there are tons of fandom sites, and you can easily find transcripts of the original 9 seasons.First, I wanted to get some basic information about the episodes, so that’s what this post will focus on. My first thought was to go to Wikipedia.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Thu, 28 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.
Hugo makes use of a variety of open source projects including:
 https://github.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
